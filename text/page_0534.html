<div class="page-content">
  <h2>Alegerea Parametrului C și Rezumatul SVM</h2>
  <p>Pagina discută selecția parametrului de regularizare C prin validare încrucișată, interacțiunea dintre C și parametrii kernel-ului, și rezumă cele trei ingrediente cheie ale SVM-urilor.</p>
  <div class="definition-box"><strong>Parametrul C:</strong> Constanta de regularizare a SVM care controlează compromisul între maximizarea marginii (C mic) și minimizarea erorilor de clasificare (C mare). Interacționează puternic cu parametrii kernel-ului (de ex., γ pentru kernel RBF).</div>
  <div class="highlight-box"><strong>Recomandare LIBSVM:</strong> Căutare pe grilă 2D cu C ∈ {2⁻⁵, 2⁻³, ..., 2¹⁵} și γ ∈ {2⁻¹⁵, 2⁻¹³, ..., 2³}. Important: standardizarea datelor înainte de utilizarea kernel-ului Gaussian sferic.</div>
  <div class="highlight-box"><strong>Cele trei ingrediente SVM:</strong> (1) Trucul kernel - previne subadaptarea asigurând un spațiu de caracteristici suficient de bogat. (2) Sparsitatea - din funcția de pierdere hinge. (3) Principiul marginii mari - maximizarea distanței minime la frontieră.</div>
  <div class="figure-box"><strong>Figura 14.15:</strong> (a) Estimare prin validare încrucișată a erorii 0-1 pentru SVM cu kernel RBF, ca funcție de γ și C. (b) Secțiune prin suprafață la γ = 5, cu linia roșie punctată indicând eroarea optimală Bayes.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Alegerea parametrului C este critică pentru performanța SVM și trebuie făcută prin validare încrucișată. C interacționează puternic cu parametrii kernel-ului: kernel-uri înguste (γ mare) necesită regularizare puternică (C mic). Rezumatul identifică trei ingrediente esențiale ale SVM: trucul kernel, sparsitatea și marginea mare.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>Cuplarea dintre C și parametrii kernel necesită căutare pe grilă bidimensională. Algoritmul de cale de regularizare (inspirat de LARS) poate selecta C eficient. Dacă caracteristicile originale sunt de dimensiune înaltă, un kernel liniar poate fi suficient.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Selecția hiperparametrilor este adesea pasul cel mai costisitor computațional în antrenarea SVM. Instrumente precum scikit-learn oferă GridSearchCV și RandomizedSearchCV pentru automatizarea acestui proces.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>În clasificarea expresiei genelor pentru diagnosticul cancerului, datele au mii de caracteristici dar puține eșantioane. Un SVM liniar (fără kernel neliniar) poate fi suficient, iar alegerea lui C prin CV cu 5 folduri este standard.</p></div>
  </div>
</div>
