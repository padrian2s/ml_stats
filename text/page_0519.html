<div class="page-content">
  <h2>Sparse Vector Machines, Comparatia L1VM/L2VM/RVM/SVM si Kernel Trick</h2>
  <p>Pagina continua cu comparatia sparse vector machines si introduce Sectiunea 14.4 (kernel trick).</p>
  <div name="highlight-box"><strong>Sparse vector machines - detalii:</strong> phi(x) = [kappa(x, x_1), ..., kappa(x, x_N)], cu N parametri de data. Selectia centroizilor prin: l1 regularization -> L1VM (Cawley and Talbot 2005), ARD/SBL -> RVM (Tipping 2001), retea RBF cu l2 -> L2VM. Se obtine sparsitate maxima cu RVM.</div>
  <div class="highlight-box"><strong>Comparatia L2VM, L1VM, RVM, SVM (Figura 14.4, 14.5):</strong> Clasificare binara cu RBF kernel: toate metodele produc performante similare. RVM este cel mai sparse (mai putine vectori de suport), L1VM si SVM intermediate, L2VM non-sparse. Performanta SVM depinde critic de parametrul C. In regresie, rezultatele sunt similare.</div>
  <div class="definition-box"><strong>Kernel trick (Sectiunea 14.4):</strong> In loc de a defini phi(x) = [kappa(x, x_1), ..., kappa(x, x_N)] si a lucra cu vectori de feature, se rescrie algoritmul inlocuind toate produsele scalare phi(x)^T phi(x') cu kappa(x, x'). Aceasta permite algoritmi sa lucreze in spatii de feature infinit-dimensionale. Cerinta: kernelul trebuie sa fie Mercer.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Comparatia empirica arata ca diferenta intre L1VM, L2VM, RVM si SVM este mica in termeni de acuratete, dar difera semnificativ in sparsitate (numarul de vectori de suport/centroizi selectati). Kernel trick-ul este ideea centrala a capitolului: permite algoritmilor sa opereze in spatii de feature implicite prin inlocuirea produselor scalare cu evaluari de kernel.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>Kernel trick necesita ca algoritmul sa depinda de date doar prin produse scalare phi(x_i)^T phi(x_j). Aceasta conditie este satisfacuta de SVM, kernel PCA, kernel ridge regression, dar nu de toate algoritmele (de exemplu, decision trees nu pot fi kernelizate direct).</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>In practica, alegerea intre L1VM, RVM si SVM depinde de necesitatile specifice: SVM pentru acuratete maxima cu software matur, RVM pentru estimari probabilistice si sparsitate, L1VM ca compromis. Kernel trick elimina necesitatea de a stoca phi(x) explicit, reducand memoria de la O(D') la O(N^2) (matricea Gram).</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In clasificarea de imagini satelitare (land cover mapping), SVM cu kernel RBF este standard industrial, oferind clasificare precisa a tipurilor de acoperire a terenului din date multispectrale cu zeci de bande spectrale.</p></div>
  </div>
</div>
