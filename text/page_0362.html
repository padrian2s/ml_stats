<div class="page-content">
  <h2>POMDP-uri, MDP-uri si exercitii de modele grafice directionate</h2>
  <p>Aceasta pagina introduce procesele de decizie Markov partial observabile (POMDP) si complet observabile (MDP), apoi incepe sectiunea de exercitii a Capitolului 10.</p>
  <div class="definition-box"><strong>POMDP (Partially Observed Markov Decision Process):</strong> Un HMM (model Markov ascuns) augmentat cu noduri de actiune si recompensa. Starile z_t sunt ascunse, observatiile x_t sunt vizibile, actiunile a_t afecteaza tranzitiile, si recompensele R_t depind de stari si actiuni. Deciziile se bazeaza pe â€žstarea de credinta" p(z_t|x_{1:t}, a_{1:t}).</div>
  <div class="definition-box"><strong>MDP (Markov Decision Process):</strong> Caz special al POMDP in care starile sunt complet observabile (z_t = x_t). Se rezolva prin programare dinamica, calculand o politica &pi;: x &rarr; a care maximizeaza recompensa cumulata asteptata.</div>
  <div class="highlight-box"><strong>Exercitiul 10.1 - Marginalizarea intr-un DGM:</strong> Cand marginalizez o variabila X dintr-un DGM (eliminand nodul), trebuie adaugate arce suplimentare intre parintii si copiii lui X pentru a pastra dependentele conditionaleinduse.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Pagina tranziteaza de la diagramele de influenta statice la cele secventiale (POMDP/MDP), apoi incepe exercitiile. POMDP-urile modeleaza ciclul perceptie-actiune al agentilor inteligenti, fiind fundamentul invatarii prin recompensa in medii partial observabile. Exercitiile cer studentilor sa aplice conceptele de d-separare, Bayes ball, si marginalizare pe DGM-uri concrete.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) POMDP generalizeaza HMM prin adaugarea actiunilor si recompenselor. 2) MDP simplifica POMDP prin observabilitate completa. 3) Rezolvarea POMDP necesita mentinerea distributiei de credinta - un obiect infinit dimensional, ceea ce face problema foarte dificila. 4) Exercitiul de marginalizare arata ca eliminarea variabilelor dintr-un graf poate necesita adaugarea de arce.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>MDP-urile sunt rezolvate zilnic in robotica (navigare autonoma), jocuri (AlphaGo), optimizarea resurselor (management energie), si publicitatea online (secventiere de reclame). POMDP-urile se aplica in dialogul om-masina, in managementul medical (tratamente secventiale), si in controlul traficului.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>Un robot de livrare autonoma (precum cele folosite pe campusurile universitare) opereaza intr-un POMDP: starea reala (pozitia exacta, obstacole) este partial observabila prin senzori imperfecti (camere, LIDAR). Robotul mentine o distributie de credinta asupra pozitiei sale si planifica actiuni (miscare, oprire) care maximizeaza probabilitatea de livrare reusita, exact conform cadrului POMDP.</p></div>
  </div>
</div>