<div class="page-content">
  <h2>Exercitii: MLE si selectia modelelor pentru distributii discrete 2D</h2>
  <p>Aceasta pagina contine exercitiul 5.8 despre estimarea MLE si selectia modelelor pentru o distributie discreta bidimensionala, comparand modele cu 2 si 4 parametri folosind cross-validare leave-one-out si BIC.</p>
  <div class="definition-box"><strong>Modelul cu 2 parametri (M_2):</strong> p(x, y | &theta;) = p(y | x, &theta;_2) p(x | &theta;_1), unde &theta;_1 este probabilitatea de heads la aruncarea monedei si &theta;_2 este probabilitatea ca observatorul sa raporteze corect. Presupune independenta conditionata.</div>
  <div class="definition-box"><strong>Modelul cu 4 parametri (M_4):</strong> p(x, y | &theta;) = &theta;_{x,y}, un model complet fara presupuneri de independenta, cu 3 parametri liberi (suma = 1). Este mai flexibil dar necesita mai multe date pentru estimare fiabila.</div>
  <div class="highlight-box"><strong>Selectia modelelor prin cross-validare LOO:</strong> L(m) = &Sigma;_i log p(x_i, y_i | m, &theta;_hat(D_{-i})). Modelul mai simplu poate fi preferat daca cel complex suprainvata: eliminarea unei observatii poate schimba dramatic MLE-ul modelului cu 4 parametri.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Exercitiul ilustreaza un compromis fundamental in statistica: un model mai complex (4 parametri) se potriveste mai bine pe datele de antrenament, dar poate avea performanta predictiva mai slaba pe date noi. Cross-validarea LOO penalizeaza automat complexitatea excesiva, iar BIC ofera o alternativa analitica. Factorizarea verosimilitii in modelul cu 2 parametri exploateaza structura de independenta conditionata.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) Verosimilitatea se factorizeaza conform structurii grafice a modelului. 2) Cu date putine, modelul simplu este preferat chiar daca modelul complex este â€žadevarat". 3) In LOO, eliminarea unei observatii poate schimba proportiile in tabelul de contingenta, afectand dramatic modelul complex. 4) BIC si CV pot da rezultate diferite dar in general coerente.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Selectia intre modele simple si complexe este omniprezenta: in NLP (unigram vs. bigram), in regresia cu numar diferit de predictori, in retelele neurale (numarul de straturi/neuroni). Principiul este universal: complexitatea modelului trebuie sa fie proportionala cu cantitatea de date disponibile.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In sondajele de opinie, observatorul (respondentul) poate raporta incorect - fie intentionat, fie din neintelegerea intrebarii. Modelul cu 2 parametri presupune ca rata de eroare a observatorului este aceeasi indiferent de raspunsul real, pe cand modelul cu 4 parametri permite rate de eroare diferite. Cu un esantion mic, primul model este mai stabil si produce predictii mai fiabile.</p></div>
  </div>
</div>