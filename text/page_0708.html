<div class="page-content">
  <h2>Gradientul log-verosimilitutii si potrivirea momentelor</h2>
  <p>Aceasta pagina deriveaza gradientul log-verosimilitutii pentru MRF-uri, introduce termenii "clamped" si "unclamped", si prezinta antrenarea modelelor partial observate.</p>
  <div class="definition-box"><strong>Termenul "clamped" (fixat):</strong> Componenta gradientului care fixeaza y la valorile observate: (1/N) Σ_i φ_c(y_i). Aceasta este media empirica a trasaturilor.</div>
  <div class="definition-box"><strong>Termenul "unclamped" (liber) / contrastiv:</strong> Componenta gradientului care lasa y liber sub modelul curent: E[φ_c(y)]. Calculul acestui termen necesita inferenta in model, ceea ce este de obicei intractabil.</div>
  <div class="highlight-box"><strong>Potrivirea momentelor (moment matching):</strong> La optimul log-verosimilitutii, asteptarea trasaturilor sub distributia empirica egaleaza asteptarea sub model: E_{p_emp}[φ_c(y)] = E_{p(·|θ)}[φ_c(y)]. Aceasta conditie este echivalenta cu principiul entropiei maxime.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Gradientul log-verosimilitutii MRF-urilor are doua componente: termenul clamped (usor de calculat, media empirica a trasaturilor) si termenul unclamped (dificil, necesita inferenta). La convergenta, modelul se potriveste cu statisticile suficiente ale datelor. Pentru modele partial observate, ambele componente necesita marginalizare peste variabilele ascunse.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>Diferenta fundamentala fata de DGM-uri: antrenarea MRF-urilor necesita inferenta la fiecare pas de gradient (pentru termenul unclamped). Potrivirea momentelor leaga MLE de principiul entropiei maxime. Modelele partial observate adauga un nivel de complexitate, deoarece si termenul clamped necesita acum inferenta.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Algoritmul de antrenare bazat pe gradient este baza antrenarii CRF-urilor, retelelor Boltzmann si altor MRF-uri. Divergenta contrastiva (contrastive divergence) este o aproximare populara a termenului unclamped, folosita in antrenarea RBM-urilor.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>La antrenarea unui model de limba bazat pe MRF, termenul clamped contorizeaza frecventele n-gramelor in corpus, iar termenul unclamped estimeaza frecventele pe care modelul le-ar produce spontan. Modelul optimal echilibreaza cele doua.</p></div>
  </div>
</div>
