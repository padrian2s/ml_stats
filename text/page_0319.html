<div class="page-content">
  <h2>Densitatea predictiva posterioara si exemplul Beta-Bernoulli</h2>
  <p>Aceasta pagina deriveaza formula generica pentru densitatea predictiva posterioara in familia exponentiala si o aplica la exemplul clasic Beta-Bernoulli.</p>
  <div class="definition-box"><strong>Densitatea predictiva posterioara (generala):</strong> p(D'|D) = [&prod; h(x_tilde_i)] Z(&tau;_tilde_0 + s_tilde(D) + s_tilde(D')) / Z(&tau;_tilde_0 + s_tilde(D)). Raportul constantelor de normalizare ale posteriorului dupa si inainte de observarea datelor noi.</div>
  <div class="definition-box"><strong>Exemplul Beta-Bernoulli:</strong> p(D'|D) = [&Gamma;(&alpha;_n + &beta;_n) / (&Gamma;(&alpha;_n)&Gamma;(&beta;_n))] &times; [&Gamma;(&alpha;_{n+m})&Gamma;(&beta;_{n+m}) / &Gamma;(&alpha;_{n+m} + &beta;_{n+m})], unde &alpha;_{n+m} = &alpha; + s + s' si &beta;_{n+m} = &beta; + (n-s) + (m-s').</div>
  <div class="highlight-box"><strong>Regula lui Laplace:</strong> Densitatea predictiva Beta-Bernoulli pentru un singur esantion viitor reduce la: p(x_tilde = 1 | D) = (&alpha; + s)/(&alpha; + &beta; + n), care este media posteriorului Beta. Cu prior uniform (&alpha;=&beta;=1), aceasta devine (s+1)/(n+2), forma clasica a regulii lui Laplace (add-one smoothing).</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Pagina demonstreaza puterea cadrului unificat: formula generica de predictie se aplica la orice membru al familiei exponentiale. Exemplul Beta-Bernoulli arata cum se obtine predictia Bayesiana a urmatoarei observatii: este o medie ponderata intre prior si frecventa empirica, nu pur si simplu frecventa empirica (care ar fi estimarea MLE). Regula lui Laplace previne predictia de 0 sau 1, care ar fi problematica in multe aplicatii.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) Densitatea predictiva se calculeaza fara a estima explicit parametrii - se integreaza peste ei. 2) Rezultatul depinde de statisticile suficiente, nu de datele individuale. 3) Regula lui Laplace adauga 1 „pseudo-observatie" de fiecare tip, evitand probabilitati zero. 4) Formula generala functioneaza pentru orice marime a setului de date viitoare D'.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Regula lui Laplace (add-one smoothing) este fundamentala in modelele de limba (evitarea probabilitatii zero pentru cuvinte nevazute), in filtrarea spam (estimarea probabilitatii cuvintelor rare), si in orice model probabilistic care trebuie sa gestioneze evenimente rare sau nevazute.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In modelele de limba, daca cuvantul „blockchain" nu a aparut niciodata in corpusul de antrenament, MLE ar da p(blockchain) = 0, facand imposibila orice propozitie care il contine. Smoothing-ul Laplace (sau variantele sale: Kneser-Ney, Witten-Bell) evita aceasta problema prin „imprumutarea" de masa de probabilitate de la cuvintele frecvente catre cele rare.</p></div>
  </div>
</div>