<div class="page-content">
  <h2>Exercitii: BIC pentru modele Gaussiene si derivarea posteriorului NIW</h2>
  <p>Aceasta pagina contine exercitii avansate despre criteriul informational Bayesian (BIC) aplicat modelelor Gaussiene si derivarea posteriorului Normal-Inverse-Wishart prin „completarea patratului" matriceal.</p>
  <div class="definition-box"><strong>Criteriul BIC (Bayesian Information Criterion):</strong> BIC = log p(D | &theta;_ML) - (d/2) log(N), unde d este numarul de parametri liberi si N numarul de esantioane. Penalizeaza modelele complexe pentru a evita suprainvatarea.</div>
  <div class="definition-box"><strong>Completarea patratului matriceala:</strong> N(x_bar - &mu;)(x_bar - &mu;)^T + &kappa;_0(&mu; - m_0)(&mu; - m_0)^T = &kappa;_N(&mu; - m_N)(&mu; - m_N)^T + (&kappa;_0 N / &kappa;_N)(x_bar - m_0)(x_bar - m_0)^T. Aceasta este generalizarea matriceala a completarii patratului scalar si este cheia derivarii posteriorului NIW.</div>
  <div class="highlight-box"><strong>Selectia modelului Gaussian cu BIC:</strong> BIC permite compararea unui model Gaussian cu covarianta plina (d = D(D+1)/2 + D parametri) vs. covarianta diagonala (d = 2D parametri). Modelul cu covarianta plina are log-verosimilitate mai mare, dar penalizarea BIC poate favoriza modelul diagonal daca N este mic relativ la D.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Exercitiul BIC demonstreaza un principiu fundamental: un model mai complex (covarianta plina vs. diagonala) se potriveste mai bine pe date, dar aceasta potrivire suplimentara „merita" doar daca numarul de date N este suficient de mare relativ la numarul suplimentar de parametri. Exercitiul de derivare a posteriorului NIW prin completarea patratului arata mecanica algebrica din spatele formulelor de actualizare prezentate anterior.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) BIC penalizeaza cu (d/2) log(N), deci penalizarea creste logaritmic cu N. 2) Numarul de parametri in covarianta plina creste patratic cu D: D(D+1)/2. 3) Completarea patratului matriceala produce un termen rezidual care se adauga la S_N. 4) Log-verosimilitatea pentru Gaussiana se poate scrie elegant folosind trucul urmei: log p = -(N/2) tr(&Sigma;^(-1) S_hat) - (N/2) log|&Sigma;|.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>BIC este folosit in selectia numarului de clustere in GMM, in alegerea structurii matricei de covarianta in analiza discriminanta, si in selectia generala a complexitatii modelelor. Completarea patratului este esentiala in derivarea algoritmilor de inferenta Bayesiana exacta pentru modele Gaussiene.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In segmentarea clientilor, un model GMM cu covarianta plina poate capta corelatii complexe intre variabilele demografice, dar cu doar 100 de clienti si 20 de variabile, covarianta plina ar avea 210 parametri per cluster - mai multi decat datele! BIC ar favoriza corect modelul diagonal, evitand suprainvatarea si producand segmente mai stabile si interpretabile.</p></div>
  </div>
</div>