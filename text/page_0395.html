<div class="page-content">
  <h2>Demonstratia Cresterii Monotone a EM</h2>
  <p>Pagina continua derivarea teoretica a EM, aratand ca limita inferioara este stransa dupa pasul E si ca pasul M creste log-verosimilitatea datelor observate.</p>
  <div class="definition-box"><strong>Pasul E optimal:</strong> Alegand q_i^t(z_i) = p(z_i|x_i, theta^t), divergenta KL devine zero si limita inferioara Q(theta^t, theta^t) = l(theta^t) - limita atinge exact log-verosimilitatea.</div>
  <div class="highlight-box"><strong>Teorema cresterii monotone:</strong> l(theta^{t+1}) >= Q(theta^{t+1}, theta^t) >= Q(theta^t, theta^t) = l(theta^t). Prima inegalitate vine din faptul ca Q este limita inferioara, a doua din maximizarea in pasul M.</div>
  <div class="highlight-box"><strong>Interpretare geometrica (Figura 11.16):</strong> Curba rosie este log-verosimilitatea reala, curba albastra este limita inferioara care atinge obiectivul in theta^t. Maximizand limita inferioara, ne mutam la theta^{t+1}, unde construim o noua limita inferioara.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Demonstratia completa a convergentei EM se bazeaza pe doua proprietati: (1) pasul E face limita inferioara stransa prin alegerea q optim, si (2) pasul M creste limita inferioara. Impreuna, acestea garanteaza ca log-verosimilitatea observata creste la fiecare iteratie, pana la atingerea unui optim local.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>EM este un exemplu de algoritm de optimizare prin minorizare-maximizare (MM). Interpretarea geometrica din Figura 11.16 arata clar diferenta fata de metoda Newton: EM optimizeaza o aproximare globala (limita inferioara), nu una locala (aproximare patratica).</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Garantia de crestere monotona este esentiala pentru implementarile practice: permite detectarea erorilor (daca log-verosimilitatea scade, exista un bug), si ofera un criteriu natural de oprire (cand cresterea devine neglijabila).</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In antrenarea modelelor de amestec pentru recunoasterea vorbirii (HMM-GMM), monitorizarea cresterii monotone a log-verosimilitudinii este practica standard pentru validarea corectitudinii antrenamentului pe milioane de cadre audio.</p></div>
  </div>
</div>
