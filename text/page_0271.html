<div class="page-content">
  <h2>Exercitii: regresie multi-output, centrare si ridge, MLE pentru varianta</h2>
  <p>Aceasta pagina contine exercitii despre regresia cu functii de baza, centrarea datelor in regresia ridge, MLE-ul pentru varianta in regresie, si MLE-ul pentru termenul de offset.</p>
  <div class="definition-box"><strong>Centrarea si regresia ridge:</strong> Daca datele sunt centrate (x_bar = 0), atunci optimizarea J(w, w_0) = ||y - Xw - w_0 1||&sup2; + &lambda; w^T w produce w_hat_0 = y_bar si w_hat = (X^T X + &lambda;I)^(-1) X^T y. Interceptul nu este regularizat.</div>
  <div class="definition-box"><strong>MLE pentru &sigma;&sup2; in regresie:</strong> &sigma;_hat&sup2; = (1/N) &Sigma;(y_i - x_i^T w_hat)&sup2;, media rezidualurilor patrate. Aceasta este varianta empirica a rezidualurilor, echivalenta cu MSE pe datele de antrenament.</div>
  <div class="highlight-box"><strong>MLE pentru offset:</strong> w_hat_0 = y_bar - x_bar^T w_hat. Interceptul modeleaza diferenta intre media outputului si predictia medie. Practic, se poate mai intai calcula w pe datele centrate, apoi determina w_0.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Exercitiile de pe aceasta pagina trateaza aspecte practice importante ale regresiei liniare. Exercitiul 7.3 demonstreaza ca centrarea datelor separa estimarea interceptului de cea a coeficientilor de panta, simplificand regresia ridge (interceptul nu trebuie regularizat). Exercitiile 7.4 si 7.5 clarifica formulele MLE pentru varianta si offset, care sunt adesea omise in prezentarile teoretice dar esentiale in implementare.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) In regresia ridge, interceptul w_0 nu trebuie regularizat (ar forta functia sa treaca prin origine). 2) Centrarea simplifica formulele si face regresia ridge echivalenta cu penalizarea L2 doar pe coeficientii de panta. 3) MLE pentru &sigma;&sup2; imparte la N (nu N-1 sau N-D), deci este un estimator deplasat. 4) Separarea estimarii w_0 de w este posibila datorita structurii problemei cu date centrate.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>In toate pachetele de ML (scikit-learn, R glmnet), centrarea si scalarea sunt pasi de preprocesare standard. Regresia ridge este implementata pe datele centrate, iar interceptul este readaugat la sfarsit. Intelegerea acestui mecanism este esentiala pentru interpretarea corecta a coeficientilor.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In modelarea pretului caselor, daca nu centram datele, interceptul ar reprezenta pretul unei case cu 0 camere, 0 mp, 0 bai - o valoare fara sens. Dupa centrare, interceptul devine pretul mediu al caselor din setul de date, iar coeficientii arata cate unitati de pret se adauga/scad per unitate de caracteristica, fata de media. Regularizarea ridge se aplica doar coeficientilor, nu interceptului.</p></div>
  </div>
</div>