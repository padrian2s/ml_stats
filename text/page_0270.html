<div class="page-content">
  <h2>Evidence procedure vs. CV si exercitii de regresie liniara</h2>
  <p>Aceasta pagina prezinta Figura 7.13 (comparatia CV vs. evidence), apoi incepe sectiunea de exercitii cu probleme despre comportamentul erorii, regresie multi-output si regresie cu functii de baza.</p>
  <div class="definition-box"><strong>Eroarea de antrenament vs. eroarea de test:</strong> Eroarea de test scade intotdeauna cu mai multe date. Eroarea de antrenament creste pentru modele suficient de complexe pe masura ce se adauga date, pana atinge un platou. Aceasta deoarece modelul complex se â€žpotriveste" excesiv pe putine date.</div>
  <div class="definition-box"><strong>Regresie multi-output:</strong> p(y | x, W) = &prod;_j N(y_j | w_j^T x, &sigma;_j&sup2;). Deoarece verosimilitatea se factorizeaza pe dimensiunile de output, MLE se obtine prin D regresii independente: W_hat = [w_hat_1, ..., w_hat_M], unde w_hat_j = (X^T X)^(-1) X^T Y_{:,j}.</div>
  <div class="highlight-box"><strong>Echivalenta CV si evidence:</strong> Figura 7.13 arata ca 5-fold CV si log evidence produc optimuri la aceleasi valori ale &lambda; si &alpha;. Aceasta confirma empiric ca verosimilitatea marginala este un proxy bun pentru performanta predictiva.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Pagina conchide discutia despre Bayes empiric cu confirmare empirica (Figura 7.13), apoi incepe exercitiile. Exercitiul 7.1 clarifica un comportament contra-intuitiv: eroarea de antrenament poate creste cu mai multe date (pentru modele complexe), in timp ce eroarea de test scade. Regresia multi-output simplifica la regresii independente cand erorile sunt necorelate intre dimensiuni.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) Discrepanta intre eroarea de antrenament si cea de test este semnul suprainvatarii. 2) Regresie multi-output cu erori necorelate = D regresii independente (paralelizabile). 3) Functiile de baza (ex: &phi;(0) = (1,0)^T, &phi;(1) = (0,1)^T) permit transformarea inputurilor discrete in vectori continui. 4) CV pe scala logaritmica (log &lambda;) este mai eficient decat pe scala liniara.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Regresia multi-output este folosita in previziunea simultana a mai multor variabile (temperatura si umiditate, sau mai multe actiuni bursiere). Diferenta eroare de antrenament vs. test este fundamentala in diagnosticarea suprainvatarii in orice model de ML.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In prognoza meteo, se prezice simultan temperatura, umiditatea, viteza vantului si presiunea atmosferica (regresie multi-output). Daca presupunem erori necorelate, putem antrena modele separate pentru fiecare variabila. In realitate, erorile sunt corelate (daca modelul subestimeaza temperatura, tinde sa subestimeze si umiditatea), iar modelele multivariate cu erori corelate pot fi mai precise.</p></div>
  </div>
</div>