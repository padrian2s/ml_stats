<div class="page-content">
  <h2>Exercitii: marginalizare DGM, Bayes Ball, paturi Markov si variabile ascunse</h2>
  <p>Aceasta pagina contine exercitii fundamentale despre proprietatile modelelor grafice directionate: marginalizarea nodurilor, d-separarea (Bayes Ball), paturile Markov si efectul variabilelor ascunse.</p>
  <div class="definition-box"><strong>Bayes Ball (Exercitiul 10.2):</strong> Algoritm pentru determinarea independentelor conditionale intr-un DGM. Se â€žruleaza o bila" prin graf urmarind regulile de blocare/transmitere la fiecare nod (observat vs. neobservat, convergent vs. divergent).</div>
  <div class="definition-box"><strong>Patura Markov (Exercitiul 10.3):</strong> Conditionala completa p(X_i | X_{-i}) in un DGM depinde doar de parintii, copiii si co-parintii (parintii copiilor) nodului i: p(X_i | X_{-i}) &prop; p(X_i | Pa(X_i)) &prod;_{Y_j in ch(X_i)} p(Y_j | Pa(Y_j)).</div>
  <div class="highlight-box"><strong>Variabile ascunse si reducerea parametrilor (Exercitiul 10.4):</strong> Un model cu variabila ascunsa H si 6 variabile observate binare are 17 parametri liberi, fata de 59 pentru modelul complet fara variabila ascunsa. Variabilele latente reduc drastic numarul de parametri prin factorizarea distributiei conjuncte.</div>
  <div class="commentary">
    <h3>Comentariu</h3>
    <div class="commentary-section"><h4>Rezumat</h4><p>Exercitiile testeaza intelegerea profunda a modelelor grafice. Bayes Ball este un algoritm vizual si intuitiv pentru determinarea independentelor conditionale. Patura Markov determina ce informatii sunt necesare pentru Gibbs sampling. Exercitiul 10.4 demonstreaza valoarea variabilelor latente: modelul cu variabila ascunsa H are de 3.5 ori mai putini parametri, ceea ce inseamna mai putine date necesare si mai putina suprainvatare.</p></div>
    <div class="commentary-section"><h4>Tipare Cheie</h4><p>1) Bayes Ball: un nod divergent neobservat transmite, unul observat blocheaza; un nod convergent neobservat blocheaza, unul observat transmite (explaining away). 2) Patura Markov = parintii + copiii + co-parintii. 3) Variabilele latente fac presupuneri de independenta conditionala care reduc exponential numarul de parametri. 4) Estimarea cu variabile latente necesita EM sau MCMC.</p></div>
    <div class="commentary-section"><h4>Aplicatii Practice</h4><p>Bayes Ball este implementat in toate pachetele de modele grafice (pgmpy, bnlearn). Patura Markov este esentiala in Gibbs sampling. Variabilele latente sunt omniprezente: factori de risc ascunsi in epidemiologie, intentia utilizatorului in NLP, clusterul de apartinenta in segmentare.</p></div>
    <div class="commentary-section"><h4>Exemplu din Lumea Reala</h4><p>In Exercitiul 10.4, modelul medical are o variabila ascunsa H (boala cardiaca) care cauzeaza multiple simptome observabile (durere toracica, respiratie dificila, oboseala). Fara H, trebuie modelate toate corelatiile intre simptome direct (59 parametri). Cu H, fiecare simptom depinde independent doar de boala (17 parametri), o simplificare masiva care reflecta mecanismul cauzal real.</p></div>
  </div>
</div>